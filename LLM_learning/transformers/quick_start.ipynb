{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH1 Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\py\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\py\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[{'label': 'POSITIVE', 'score': 0.9998639822006226}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\py\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# æƒ…æ„Ÿåˆ†æ\n",
    "classifier = pipeline(task=\"sentiment-analysis\")\n",
    "result = classifier(\"\"\"we'd like to introduce our new goods to you! hope you like \n",
    "                    these\"\"\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result: \n",
    "```python\n",
    "[{'label': 'POSITIVE', 'score': 0.9998639822006226}]\n",
    "```\n",
    "labelä¸ºæƒ…æ„Ÿåˆ†ç±»æ ‡ç­¾, scoreä¸ºç½®ä¿¡åº¦, å³æ¦‚ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, score: 0.9998\n",
      "label: NEGATIVE, score: 0.5309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nround(number, ndigits=None): å°†numberä¿ç•™ndigitsä½åè¿”å›\\n    ndigitså¯ä»¥æ˜¯è´Ÿæ•°\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¯¹å¤šä¸ªè¾“å…¥çš„æƒ…å†µ, å¯å°†è¾“å…¥ä½œä¸ºåˆ—è¡¨ä¼ å…¥pipelineå‡½æ•°\n",
    "# è¿™ä¼šè¿”å›ä¸€ä¸ªåŒ…å«å¤šä¸ªå­—å…¸çš„åˆ—è¡¨\n",
    "inputs = [\n",
    "    \"We are happy to show the transformers library.\",\n",
    "    \"We hope you don't hate it.\",\n",
    "]\n",
    "results = classifier(inputs)\n",
    "\n",
    "for result in results:\n",
    "    print(\n",
    "        f\"\"\"label: {result['label']}, score: {round(result['score'], 4)}\"\"\"\n",
    "    )\n",
    "\"\"\"\n",
    "round(number, ndigits=None): å°†numberä¿ç•™ndigitsä½åè¿”å›\n",
    "    ndigitså¯ä»¥æ˜¯è´Ÿæ•°\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results: \n",
    "\n",
    "```python\n",
    "label: POSITIVE, score: 0.9998\n",
    "label: NEGATIVE, score: 0.5309\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipelineå‡½æ•°è¿˜å¯ä»¥å¯¹æ•´ä¸ªæ•°æ®é›†æ‰§è¡ŒæŒ‡å®šä»»åŠ¡\n",
    "\n",
    "å¯¹äºæ•°æ®é‡è¾ƒå¤§çš„æƒ…å†µ(å¦‚è¯­éŸ³æˆ–è§†è§‰æ•°æ®), åˆ™éœ€è¦å°†ç”Ÿæˆå™¨ä¼ é€’ç»™æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨AutoModelForSequenceClassifierå’ŒAutoTokenizeråŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œå¯¹åº”çš„åˆ†è¯å™¨(åœ¨ä¸‹ä¸€èŠ‚è¯¦ç»†è®¨è®º)\n",
    "\n",
    "ç¤ºä¾‹:\n",
    "### Pytorch\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "```\n",
    "\n",
    "### Tensorflow\n",
    "```python\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "```\n",
    "\n",
    "åœ¨ä½¿ç”¨pipeline()æ—¶æŒ‡å®šæ¨¡å‹å’Œåˆ†è¯å™¨å³å¯ç”¨äºæ›´å¤šè¯­è¨€çš„ä»»åŠ¡\n",
    "`classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ä»£ç å®ç°ä¸Š, AutoModelForSequenceClassificationå’ŒAutoTokenizerç±»ååŒä½œç”¨, ä¸ºpipeline()æä¾›æ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "\n",
    "AutoClassæ˜¯ä¸€ä¸ªå¿«æ·æ–¹å¼, èƒ½å¤Ÿè‡ªåŠ¨ä»æ¨¡å‹åç§°æˆ–è·¯å¾„ä¸­æ£€ç´¢é¢„è®­ç»ƒæ¨¡å‹çš„æ¶æ„, æˆ‘ä»¬åªéœ€è¦ä¸ºéœ€è¦å®Œæˆçš„ä»»åŠ¡é€‰æ‹©åˆé€‚çš„Autoclasså’Œç›¸å…³çš„é¢„å¤„ç†ç±»å³å¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoTokenizer\n",
    "\n",
    "åˆ†è¯å™¨(tokenizer)è´Ÿè´£å°†é¢„å¤„ç†æ–‡æœ¬ä»¥æ•°ç»„å½¢å¼è¾“å…¥æ¨¡å‹ä¸­, åˆ†è¯è¿‡ç¨‹æ”¶åˆ°å¤šç§è§„åˆ™çš„åˆ¶çº¦, åŒ…æ‹¬å¦‚ä½•åˆ†å‰²å•è¯ä»¥åŠåœ¨ä½•ç§çº§åˆ«ä¸Šåˆ†å‰²å•è¯(è¯¦ç»†ä¿¡æ¯å‚é˜…[åˆ†è¯å™¨æ¦‚è¿°](tokenizer_summary.ipynb)), æœ€é‡è¦çš„æ˜¯, ä½ éœ€è¦ä½¿ç”¨ä¸æ¨¡å‹é¢„è®­ç»ƒæ—¶ç›¸åŒçš„æ¨¡å‹åç§°å®ä¾‹åŒ–åˆ†è¯å™¨, ç¡®ä¿åˆ†è¯è§„åˆ™ç›¸åŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨AutoTokenizeråŠ è½½åˆ†è¯å™¨\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# å°†æ–‡æœ¬ä¼ é€’ç»™åˆ†è¯å™¨\n",
    "text = \"We are very happy to show you the ğŸ¤— Transformers library.\"\n",
    "encoding = tokenizer(text)\n",
    "\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result:\n",
    "```python\n",
    "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], \n",
    "'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "```\n",
    "åˆ†è¯å™¨è¿”å›äº†ä¸€ä¸ªå­—å…¸, åŒ…å«`input_ids`, `token_type_ids`, `attention_mask`\n",
    "- `input_ids(è¾“å…¥ID)`: è¯¥å•è¯åœ¨åˆ†è¯å™¨è¯å…¸ä¸­çš„ä½ç½®\n",
    "- `attention_mask(æ³¨æ„åŠ›æ©ç )`: è¯¥å•è¯æ˜¯å¦åº”è¯¥å…³æ³¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npadding=True: åœ¨æ–‡æœ¬åºåˆ—ä¸¤ç«¯æ·»åŠ å¡«å……å­—ç¬¦, ä½¿æ¯ä¸ªæ–‡æœ¬åºåˆ—é•¿åº¦ç­‰äº\\'max_length\\'\\ntruncation=True: æˆªæ–­æ–‡æœ¬é•¿åº¦è¶…è¿‡\\'max_length\\'çš„éƒ¨åˆ†, ä½¿é•¿åº¦ç­‰äº\\'max_length\\'\\nmax_length=512: è®¾å®šæ–‡æœ¬åºåˆ—çš„æœ€å¤§é•¿åº¦(å•ä½:å­—ç¬¦)\\nreturn_tensors=\"pt\": æŒ‡å®šè¿”å›æ–‡æœ¬åºåˆ—ç±»å‹ä¸ºPyTorchå¼ é‡\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åˆ†è¯å™¨è¿˜å¯ä»¥æ¥å—ä¸€ä¸ªè¾“å…¥åˆ—è¡¨, å¹¶å¯¹æ–‡æœ¬è¿›è¡Œå¡«å……å’Œæˆªæ–­, ç¡®ä¿æ–‡æœ¬é•¿åº¦å‡åŒ€\n",
    "# PyTorch\n",
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the ğŸ¤— Transformers library.\",\n",
    "     \"We hope you don't hate it\",],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\"\"\"\n",
    "padding=True: åœ¨æ–‡æœ¬åºåˆ—ä¸¤ç«¯æ·»åŠ å¡«å……å­—ç¬¦, ä½¿æ¯ä¸ªæ–‡æœ¬åºåˆ—é•¿åº¦ç­‰äº'max_length'\n",
    "truncation=True: æˆªæ–­æ–‡æœ¬é•¿åº¦è¶…è¿‡'max_length'çš„éƒ¨åˆ†, ä½¿é•¿åº¦ç­‰äº'max_length'\n",
    "max_length=512: è®¾å®šæ–‡æœ¬åºåˆ—çš„æœ€å¤§é•¿åº¦(å•ä½:å­—ç¬¦)\n",
    "return_tensors=\"pt\": æŒ‡å®šè¿”å›æ–‡æœ¬åºåˆ—ç±»å‹ä¸ºPyTorchå¼ é‡\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "tf_batch = tokenizer(\n",
    "    [\"We are very happy to show you the ğŸ¤— Transformers library.\",\n",
    "     \"We hope you don't hate it\",],\n",
    "     padding=True,\n",
    "     truncation=True,\n",
    "     max_length=512,\n",
    "     return_tensors=\"tf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ³¨**: æœ‰å…³åˆ†è¯å™¨çš„è¯¦ç»†ä¿¡æ¯, å‚é˜…[é¢„å¤„ç†æ•™ç¨‹](preprocess.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoModel\n",
    "\n",
    "Transformersæä¾›äº†ä¸€ç§ç®€å•ä¸”ç»Ÿä¸€çš„åŠ è½½é¢„è®­ç»ƒå®ä¾‹çš„æ–¹æ³•, åŠ è½½æ–¹å¼ä¸AutoTokenizerç±»ä¼¼, å”¯ä¸€çš„åŒºåˆ«æ˜¯éœ€è¦ä¸ºä»»åŠ¡é€‰æ‹©æ­£ç¡®çš„AutoModel\n",
    "\n",
    "å¯¹äºæ–‡æœ¬åˆ†ç±»ä»»åŠ¡, åº”è¯¥é€‰æ‹©åŠ è½½AutoModelForSequenceClassification\n",
    "\n",
    "åœ¨é»˜è®¤æƒ…å†µä¸‹, æ— è®ºæƒé‡(weights)ä»¥ä»€ä¹ˆæ•°æ®ç±»å‹(å¦‚`torch.float16`)å­˜å‚¨, éƒ½ä¼šä»¥å…¨ç²¾åº¦(`torch.float32`)è¿›è¡ŒåŠ è½½\n",
    "\n",
    "å°†`torch_dtype=\"auto\"`è®¾ç½®ä¸ºæ¨¡å‹åŠ è½½`config.json`ä¸­å®šä¹‰çš„æ•°æ®ç±»å‹, å¯ä»¥è‡ªåŠ¨åŠ è½½æœ€èŠ‚çœå†…å­˜çš„æ•°æ®ç±»å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨, å°†é¢„å¤„ç†åçš„æ•°æ®æ‰¹é‡è¾“å…¥ä¼ é€’ç»™æ¨¡å‹, åœ¨ä¼ é€’æ—¶éœ€è¦æ·»åŠ `**`è§£åŒ…å­—å…¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.6222, -2.7745, -0.8967,  2.0137,  3.3064],\n",
       "        [-0.0182, -0.2979, -0.1277, -0.1001,  0.3065]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_outputs = pt_model(**pt_batch)\n",
    "\n",
    "pt_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯¥æ¨¡å‹ç”¨`logits`å±æ€§è¾“å‡ºæœ€ç»ˆæ¿€æ´»å€¼, å¯ä½¿ç”¨softmaxå‡½æ•°å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n",
      "        [0.2017, 0.1525, 0.1808, 0.1859, 0.2791]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "\"\"\"\n",
    "dim=-1: æ²¿ç€æœ€åä¸€ä¸ªç»´åº¦è¿›è¡Œè®¡ç®—\n",
    "\"\"\"\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç›¸åº”åœ°, TensorFlowä¸­åŒæ ·æä¾›äº†ä¸PyTorchç›¸åŒçš„TFAutoModelæ¥å£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_outputs = tf_model(tf_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å’ŒPyTorchä¸€æ ·, ä½¿ç”¨softmaxå‡½æ•°è·å–æ¦‚ç‡å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
